{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "import sys, os\n",
    "\n",
    "import importlib\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/device:GPU:0', '/device:GPU:1']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## here you are testing whether you have gpus or no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22. 28.]\n",
      " [49. 64.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "    c = tf.matmul(a, b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print (sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_drive_path = os.path.join('/home', 'pipusteky', 'sambashare')\n",
    "b_drive_path = os.path.join('/media', 'b_drive', 'sambashare_b')\n",
    "\n",
    "machine_g_path = os.path.join(b_drive_path, 'MACHINE_G_DRIVE', 'MACHINE_G_DRIVE')\n",
    "\n",
    "wiki_corpus_path = os.path.join(fast_drive_path, 'WORK', 'wikipedia_corpus')\n",
    "zipped_wiki_corpus_path = os.path.join(wiki_corpus_path, 'enwiki-latest-pages-articles.xml.bz2')\n",
    "\n",
    "bert_model_path = os.path.join(machine_g_path, 'BERT_MODEL')\n",
    "\n",
    "bert_modules_path = os.path.join(bert_model_path, 'MODULES')\n",
    "\n",
    "# /media/b_drive/sambashare_b/UNTRACED_MACHINE_G_DRIVE_FILES/BERT/DATA\n",
    "untraced_folder = os.path.join(b_drive_path, 'UNTRACED_MACHINE_G_DRIVE_FILES')\n",
    "bert_untraced_folder = os.path.join(untraced_folder, 'BERT')\n",
    "bert_untraced_wiki_folder = os.path.join(bert_untraced_folder,'DATA', 'WIKI_CORPUS')\n",
    "\n",
    "# add path for w2v model\n",
    "w2v_model_path = os.path.join(b_drive_path, 'MODELS', 'GOOGLE_W2V_PRETRAINED',\\\n",
    "                              'GoogleNews-vectors-negative300.bin') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(bert_modules_path)\n",
    "\n",
    "import wikipedia_corpus as wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['encoder.py',\n",
       " '__pycache__',\n",
       " 'wikipedia_corpus.py',\n",
       " 'bert_utils.py',\n",
       " '._wikipedia_corpus.py']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(bert_modules_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bert_utils as bert_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(wiki_corpus_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['enwiki-latest-pages-articles.xml.bz2']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(wiki_corpus_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOU SHOULD TAKE THE WIKIPEDIA CORPUS AND DUMP IT INTO TF.RECORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(wiki)\n",
    "wiki_iter = wiki.wiki_corpus_iterator(os.path.join(wiki_corpus_path, 'enwiki-latest-pages-articles.xml.bz2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " (['anarchism',\n",
       "   'is',\n",
       "   'political',\n",
       "   'philosophy',\n",
       "   'that',\n",
       "   'advocates',\n",
       "   'self',\n",
       "   'governed',\n",
       "   'societies',\n",
       "   'based',\n",
       "   'on',\n",
       "   'voluntary',\n",
       "   'cooperative',\n",
       "   'institutions',\n",
       "   'rejecting',\n",
       "   'unjust',\n",
       "   'hierarchy.',\n",
       "   'these',\n",
       "   'institutions',\n",
       "   'are',\n",
       "   'often',\n",
       "   'described',\n",
       "   'as',\n",
       "   'stateless',\n",
       "   'societies',\n",
       "   'although',\n",
       "   'several',\n",
       "   'authors',\n",
       "   'have',\n",
       "   'defined',\n",
       "   'them',\n",
       "   'more',\n",
       "   'specifically',\n",
       "   'as',\n",
       "   'institutions',\n",
       "   'based',\n",
       "   'on',\n",
       "   'non',\n",
       "   'hierarchical',\n",
       "   'or',\n",
       "   'free',\n",
       "   'associations.',\n",
       "   'anarchism',\n",
       "   'holds',\n",
       "   'capitalism',\n",
       "   'the',\n",
       "   'state',\n",
       "   'and',\n",
       "   'representative',\n",
       "   'democracy',\n",
       "   'to',\n",
       "   'be',\n",
       "   'undesirable',\n",
       "   'unnecessary',\n",
       "   'and',\n",
       "   'harmful.',\n",
       "   'while',\n",
       "   'opposition',\n",
       "   'to',\n",
       "   'the',\n",
       "   'state',\n",
       "   'is',\n",
       "   'central',\n",
       "   'anarchism',\n",
       "   'specifically',\n",
       "   'entails',\n",
       "   'opposing',\n",
       "   'authority',\n",
       "   'or',\n",
       "   'hierarchical',\n",
       "   'organisation',\n",
       "   'in',\n",
       "   'the',\n",
       "   'conduct',\n",
       "   'of',\n",
       "   'all',\n",
       "   'human',\n",
       "   'relations.',\n",
       "   'anarchism',\n",
       "   'is',\n",
       "   'usually',\n",
       "   'considered',\n",
       "   'far',\n",
       "   'left',\n",
       "   'ideology',\n",
       "   'and',\n",
       "   'much',\n",
       "   'of',\n",
       "   'anarchist',\n",
       "   'economics',\n",
       "   'and',\n",
       "   'anarchist',\n",
       "   'legal',\n",
       "   'philosophy',\n",
       "   'reflects',\n",
       "   'anti',\n",
       "   'authoritarian',\n",
       "   'interpretations',\n",
       "   'of',\n",
       "   'communism',\n",
       "   'collectivism',\n",
       "   'syndicalism',\n",
       "   'mutualism',\n",
       "   'or',\n",
       "   'participatory',\n",
       "   'economics.',\n",
       "   'anarchism',\n",
       "   'does',\n",
       "   'not',\n",
       "   'offer',\n",
       "   'fixed',\n",
       "   'body',\n",
       "   'of',\n",
       "   'doctrine',\n",
       "   'from',\n",
       "   'single',\n",
       "   'particular',\n",
       "   'world',\n",
       "   'view',\n",
       "   'instead',\n",
       "   'fluxing',\n",
       "   'and',\n",
       "   'flowing',\n",
       "   'as',\n",
       "   'philosophy.',\n",
       "   'many',\n",
       "   'types',\n",
       "   'and',\n",
       "   'traditions',\n",
       "   'of',\n",
       "   'anarchism',\n",
       "   'exist',\n",
       "   'not',\n",
       "   'all',\n",
       "   'of',\n",
       "   'which',\n",
       "   'are',\n",
       "   'mutually',\n",
       "   'exclusive.',\n",
       "   'anarchist',\n",
       "   'schools',\n",
       "   'of',\n",
       "   'thought',\n",
       "   'can',\n",
       "   'differ',\n",
       "   'fundamentally',\n",
       "   'supporting',\n",
       "   'anything',\n",
       "   'from',\n",
       "   'extreme',\n",
       "   'individualism',\n",
       "   'to',\n",
       "   'complete',\n",
       "   'collectivism.',\n",
       "   'strains',\n",
       "   'of',\n",
       "   'anarchism',\n",
       "   'have',\n",
       "   'often',\n",
       "   'been',\n",
       "   'divided',\n",
       "   'into',\n",
       "   'the',\n",
       "   'categories',\n",
       "   'of',\n",
       "   'social',\n",
       "   'and',\n",
       "   'individualist',\n",
       "   'anarchism',\n",
       "   'or',\n",
       "   'similar',\n",
       "   'dual',\n",
       "   'etymology',\n",
       "   'and',\n",
       "   'terminology',\n",
       "   'the',\n",
       "   'word',\n",
       "   'anarchism',\n",
       "   'is',\n",
       "   'composed',\n",
       "   'from',\n",
       "   'the',\n",
       "   'word',\n",
       "   'anarchy',\n",
       "   'and',\n",
       "   'the',\n",
       "   'suffix',\n",
       "   'ism',\n",
       "   'themselves',\n",
       "   'derived',\n",
       "   'respectively',\n",
       "   'from',\n",
       "   'the',\n",
       "   'greek',\n",
       "   'i.e.',\n",
       "   'anarchy',\n",
       "   'from',\n",
       "   'anarchos',\n",
       "   'meaning',\n",
       "   'one',\n",
       "   'without',\n",
       "   'rulers',\n",
       "   'from',\n",
       "   'the',\n",
       "   'privative',\n",
       "   'prefix',\n",
       "   'ἀν',\n",
       "   'an',\n",
       "   'i.e.',\n",
       "   'without',\n",
       "   'and',\n",
       "   'archos',\n",
       "   'i.e.',\n",
       "   'leader',\n",
       "   'ruler',\n",
       "   'cf.',\n",
       "   'archon',\n",
       "   'or',\n",
       "   'arkhē',\n",
       "   'i.e.',\n",
       "   'authority',\n",
       "   'sovereignty',\n",
       "   'realm',\n",
       "   'magistracy',\n",
       "   'and',\n",
       "   'the',\n",
       "   'suffix',\n",
       "   'or',\n",
       "   'ismos',\n",
       "   'isma',\n",
       "   'from',\n",
       "   'the',\n",
       "   'verbal',\n",
       "   'infinitive',\n",
       "   'suffix',\n",
       "   'izein',\n",
       "   'the',\n",
       "   'first',\n",
       "   'known',\n",
       "   'use',\n",
       "   'of',\n",
       "   'this',\n",
       "   'word',\n",
       "   'was',\n",
       "   'in',\n",
       "   'various',\n",
       "   'factions',\n",
       "   'within',\n",
       "   'the',\n",
       "   'french',\n",
       "   'revolution',\n",
       "   'labelled',\n",
       "   'opponents',\n",
       "   'as',\n",
       "   'anarchists',\n",
       "   'as',\n",
       "   'maximilien',\n",
       "   'robespierre',\n",
       "   'did',\n",
       "   'the',\n",
       "   'hébertists',\n",
       "   'although',\n",
       "   'few',\n",
       "   'shared',\n",
       "   'many',\n",
       "   'views',\n",
       "   'of',\n",
       "   'later',\n",
       "   'anarchists.',\n",
       "   'there',\n",
       "   'would',\n",
       "   'be',\n",
       "   'many',\n",
       "   'revolutionaries',\n",
       "   'of',\n",
       "   'the',\n",
       "   'early',\n",
       "   'nineteenth',\n",
       "   'century',\n",
       "   'who',\n",
       "   'contributed',\n",
       "   'to',\n",
       "   'the',\n",
       "   'anarchist',\n",
       "   'doctrines',\n",
       "   'of',\n",
       "   'the',\n",
       "   'next',\n",
       "   'generation',\n",
       "   'such',\n",
       "   'as',\n",
       "   'william',\n",
       "   'godwin',\n",
       "   'and',\n",
       "   'wilhelm',\n",
       "   'weitling',\n",
       "   'but',\n",
       "   'they',\n",
       "   'did',\n",
       "   'not',\n",
       "   'use',\n",
       "   'the',\n",
       "   'word',\n",
       "   'anarchist',\n",
       "   'or',\n",
       "   'anarchism',\n",
       "   'in',\n",
       "   'describing',\n",
       "   'themselves',\n",
       "   'or',\n",
       "   'their',\n",
       "   'beliefs.',\n",
       "   'the',\n",
       "   'first',\n",
       "   'political',\n",
       "   'philosopher',\n",
       "   'to',\n",
       "   'call',\n",
       "   'himself',\n",
       "   'an',\n",
       "   'anarchist',\n",
       "   'was',\n",
       "   'pierre',\n",
       "   'joseph',\n",
       "   'proudhon',\n",
       "   'marking',\n",
       "   'the',\n",
       "   'formal',\n",
       "   'birth',\n",
       "   'of',\n",
       "   'anarchism',\n",
       "   'in',\n",
       "   'the',\n",
       "   'mid',\n",
       "   'nineteenth',\n",
       "   'century.',\n",
       "   'since',\n",
       "   'the',\n",
       "   'and',\n",
       "   'beginning',\n",
       "   'in',\n",
       "   'france',\n",
       "   'the',\n",
       "   'term',\n",
       "   'libertarianism',\n",
       "   'has',\n",
       "   'often',\n",
       "   'been',\n",
       "   'used',\n",
       "   'as',\n",
       "   'synonym',\n",
       "   'for',\n",
       "   'anarchism',\n",
       "   'and',\n",
       "   'its',\n",
       "   'use',\n",
       "   'as',\n",
       "   'synonym',\n",
       "   'is',\n",
       "   'still',\n",
       "   'common',\n",
       "   'outside',\n",
       "   'the',\n",
       "   'united',\n",
       "   'states.',\n",
       "   'on',\n",
       "   'the',\n",
       "   'other',\n",
       "   'hand',\n",
       "   'some',\n",
       "   'use',\n",
       "   'libertarianism',\n",
       "   'to',\n",
       "   'refer',\n",
       "   'to',\n",
       "   'individualistic',\n",
       "   'free',\n",
       "   'market',\n",
       "   'philosophy',\n",
       "   'only',\n",
       "   'referring',\n",
       "   'to',\n",
       "   'free',\n",
       "   'market',\n",
       "   'anarchism',\n",
       "   'as',\n",
       "   'libertarian',\n",
       "   'anarchism.',\n",
       "   'history',\n",
       "   'origins',\n",
       "   'the',\n",
       "   'earliest',\n",
       "   'anarchist',\n",
       "   'themes',\n",
       "   'can',\n",
       "   'be',\n",
       "   'found',\n",
       "   'in',\n",
       "   'the',\n",
       "   'th',\n",
       "   'century',\n",
       "   'bc',\n",
       "   'among',\n",
       "   'the',\n",
       "   'works',\n",
       "   'of',\n",
       "   'taoist',\n",
       "   'philosopher',\n",
       "   'laozi',\n",
       "   'and',\n",
       "   'in',\n",
       "   'later',\n",
       "   'centuries',\n",
       "   'by',\n",
       "   'zhuangzi',\n",
       "   'and',\n",
       "   'bao',\n",
       "   'jingyan.',\n",
       "   'zhuangzi',\n",
       "   'philosophy',\n",
       "   'has',\n",
       "   'been',\n",
       "   'described',\n",
       "   'by',\n",
       "   'various',\n",
       "   'sources',\n",
       "   'as',\n",
       "   'anarchist.',\n",
       "   'zhuangzi',\n",
       "   'wrote',\n",
       "   'petty',\n",
       "   'thief',\n",
       "   'is',\n",
       "   'put',\n",
       "   'in',\n",
       "   'jail.',\n",
       "   'great',\n",
       "   'brigand',\n",
       "   'becomes',\n",
       "   'ruler',\n",
       "   'of',\n",
       "   'nation',\n",
       "   'diogenes',\n",
       "   'of',\n",
       "   'sinope',\n",
       "   'and',\n",
       "   'the',\n",
       "   'cynics',\n",
       "   'as',\n",
       "   'well',\n",
       "   'as',\n",
       "   'their',\n",
       "   'contemporary',\n",
       "   'zeno',\n",
       "   'of',\n",
       "   'citium',\n",
       "   'the',\n",
       "   'founder',\n",
       "   'of',\n",
       "   'stoicism',\n",
       "   'also',\n",
       "   'introduced',\n",
       "   'similar',\n",
       "   'topics.',\n",
       "   'jesus',\n",
       "   'is',\n",
       "   'sometimes',\n",
       "   'considered',\n",
       "   'the',\n",
       "   'first',\n",
       "   'anarchist',\n",
       "   'in',\n",
       "   'the',\n",
       "   'christian',\n",
       "   'anarchist',\n",
       "   'tradition.',\n",
       "   'georges',\n",
       "   'lechartier',\n",
       "   'wrote',\n",
       "   'the',\n",
       "   'true',\n",
       "   'founder',\n",
       "   'of',\n",
       "   'anarchy',\n",
       "   'was',\n",
       "   'jesus',\n",
       "   'christ',\n",
       "   'and',\n",
       "   '...',\n",
       "   'the',\n",
       "   'first',\n",
       "   'anarchist',\n",
       "   'society',\n",
       "   'was',\n",
       "   'that',\n",
       "   'of',\n",
       "   'the',\n",
       "   'apostles',\n",
       "   'in',\n",
       "   'early',\n",
       "   'islamic',\n",
       "   'history',\n",
       "   'some',\n",
       "   'manifestations',\n",
       "   'of',\n",
       "   'anarchic',\n",
       "   'thought',\n",
       "   'are',\n",
       "   'found',\n",
       "   'during',\n",
       "   'the',\n",
       "   'islamic',\n",
       "   'civil',\n",
       "   'war',\n",
       "   'over',\n",
       "   'the',\n",
       "   'caliphate',\n",
       "   'where',\n",
       "   'the',\n",
       "   'kharijites',\n",
       "   'insisted',\n",
       "   'that',\n",
       "   'the',\n",
       "   'imamate',\n",
       "   'is',\n",
       "   'right',\n",
       "   'for',\n",
       "   'each',\n",
       "   'individual',\n",
       "   'within',\n",
       "   'the',\n",
       "   'islamic',\n",
       "   'society.',\n",
       "   'woodcut',\n",
       "   'from',\n",
       "   'diggers',\n",
       "   'document',\n",
       "   'by',\n",
       "   'william',\n",
       "   'everard',\n",
       "   'the',\n",
       "   'french',\n",
       "   'renaissance',\n",
       "   'political',\n",
       "   'philosopher',\n",
       "   'étienne',\n",
       "   'de',\n",
       "   'la',\n",
       "   'boétie',\n",
       "   'wrote',\n",
       "   'in',\n",
       "   'his',\n",
       "   'most',\n",
       "   'famous',\n",
       "   'work',\n",
       "   'the',\n",
       "   'discourse',\n",
       "   'on',\n",
       "   'voluntary',\n",
       "   'servitude',\n",
       "   'what',\n",
       "   'some',\n",
       "   'historians',\n",
       "   'consider',\n",
       "   'an',\n",
       "   'important',\n",
       "   'anarchist',\n",
       "   'precedent.',\n",
       "   'the',\n",
       "   'radical',\n",
       "   'protestant',\n",
       "   'christian',\n",
       "   'gerrard',\n",
       "   'winstanley',\n",
       "   'and',\n",
       "   'his',\n",
       "   'group',\n",
       "   'the',\n",
       "   'diggers',\n",
       "   'are',\n",
       "   'cited',\n",
       "   'by',\n",
       "   'various',\n",
       "   'authors',\n",
       "   'as',\n",
       "   'proposing',\n",
       "   'anarchist',\n",
       "   'social',\n",
       "   'measures',\n",
       "   'in',\n",
       "   'the',\n",
       "   'th',\n",
       "   'century',\n",
       "   'in',\n",
       "   'england.',\n",
       "   'the',\n",
       "   'term',\n",
       "   'anarchist',\n",
       "   'first',\n",
       "   'entered',\n",
       "   'the',\n",
       "   'english',\n",
       "   'language',\n",
       "   'in',\n",
       "   'during',\n",
       "   'the',\n",
       "   'english',\n",
       "   'civil',\n",
       "   'war',\n",
       "   'as',\n",
       "   'term',\n",
       "   'of',\n",
       "   'abuse',\n",
       "   'used',\n",
       "   'by',\n",
       "   'royalists',\n",
       "   'against',\n",
       "   'their',\n",
       "   'roundhead',\n",
       "   'opponents.',\n",
       "   'by',\n",
       "   'the',\n",
       "   'time',\n",
       "   'of',\n",
       "   'the',\n",
       "   'french',\n",
       "   'revolution',\n",
       "   'some',\n",
       "   'such',\n",
       "   'as',\n",
       "   'the',\n",
       "   'enraged',\n",
       "   'ones',\n",
       "   'began',\n",
       "   'to',\n",
       "   'use',\n",
       "   'the',\n",
       "   'term',\n",
       "   'positively',\n",
       "   'in',\n",
       "   'opposition',\n",
       "   'to',\n",
       "   'jacobin',\n",
       "   'centralisation',\n",
       "   'of',\n",
       "   'power',\n",
       "   'seeing',\n",
       "   'revolutionary',\n",
       "   'government',\n",
       "   'as',\n",
       "   'oxymoronic.',\n",
       "   'by',\n",
       "   'the',\n",
       "   'turn',\n",
       "   'of',\n",
       "   'the',\n",
       "   'th',\n",
       "   'century',\n",
       "   'the',\n",
       "   'english',\n",
       "   'word',\n",
       "   'anarchism',\n",
       "   'had',\n",
       "   'lost',\n",
       "   'its',\n",
       "   'initial',\n",
       "   'negative',\n",
       "   'connotation.',\n",
       "   'modern',\n",
       "   'anarchism',\n",
       "   'emerged',\n",
       "   'from',\n",
       "   'the',\n",
       "   'secular',\n",
       "   'or',\n",
       "   'religious',\n",
       "   'thought',\n",
       "   'of',\n",
       "   'the',\n",
       "   'enlightenment',\n",
       "   'particularly',\n",
       "   'jean',\n",
       "   'jacques',\n",
       "   'rousseau',\n",
       "   'arguments',\n",
       "   'for',\n",
       "   'the',\n",
       "   'moral',\n",
       "   'centrality',\n",
       "   'of',\n",
       "   'freedom.',\n",
       "   'william',\n",
       "   'godwin',\n",
       "   'was',\n",
       "   'the',\n",
       "   'first',\n",
       "   'to',\n",
       "   'formulate',\n",
       "   'the',\n",
       "   'political',\n",
       "   'and',\n",
       "   'economical',\n",
       "   'conceptions',\n",
       "   'of',\n",
       "   'anarchism',\n",
       "   'even',\n",
       "   'though',\n",
       "   'he',\n",
       "   'did',\n",
       "   'not',\n",
       "   'give',\n",
       "   'that',\n",
       "   'name',\n",
       "   'to',\n",
       "   'the',\n",
       "   'ideas',\n",
       "   'developed',\n",
       "   'in',\n",
       "   'his',\n",
       "   'work',\n",
       "   'according',\n",
       "   'to',\n",
       "   'kropotkin.',\n",
       "   'as',\n",
       "   'part',\n",
       "   'of',\n",
       "   'the',\n",
       "   'political',\n",
       "   'turmoil',\n",
       "   'of',\n",
       "   'the',\n",
       "   'in',\n",
       "   'the',\n",
       "   'wake',\n",
       "   'of',\n",
       "   'the',\n",
       "   'french',\n",
       "   'revolution',\n",
       "   'william',\n",
       "   'godwin',\n",
       "   'developed',\n",
       "   'the',\n",
       "   'first',\n",
       "   'expression',\n",
       "   'of',\n",
       "   'modern',\n",
       "   'anarchist',\n",
       "   'thought.',\n",
       "   'according',\n",
       "   'to',\n",
       "   'peter',\n",
       "   'kropotkin',\n",
       "   'godwin',\n",
       "   'was',\n",
       "   'the',\n",
       "   'first',\n",
       "   'to',\n",
       "   'formulate',\n",
       "   'the',\n",
       "   'political',\n",
       "   'and',\n",
       "   'economical',\n",
       "   'conceptions',\n",
       "   'of',\n",
       "   'anarchism',\n",
       "   'even',\n",
       "   'though',\n",
       "   'he',\n",
       "   'did',\n",
       "   'not',\n",
       "   'give',\n",
       "   'that',\n",
       "   'name',\n",
       "   'to',\n",
       "   'the',\n",
       "   'ideas',\n",
       "   'developed',\n",
       "   'in',\n",
       "   'his',\n",
       "   'work',\n",
       "   'while',\n",
       "   'godwin',\n",
       "   'attached',\n",
       "   'his',\n",
       "   'anarchist',\n",
       "   'ideas',\n",
       "   'to',\n",
       "   'an',\n",
       "   'early',\n",
       "   'edmund',\n",
       "   'burke.',\n",
       "   'godwin',\n",
       "   'is',\n",
       "   'generally',\n",
       "   'regarded',\n",
       "   'as',\n",
       "   'the',\n",
       "   'founder',\n",
       "   'of',\n",
       "   'the',\n",
       "   'school',\n",
       "   'of',\n",
       "   'thought',\n",
       "   'known',\n",
       "   'as',\n",
       "   'philosophical',\n",
       "   'anarchism.',\n",
       "   'he',\n",
       "   'argued',\n",
       "   'in',\n",
       "   'political',\n",
       "   'justice',\n",
       "   'that',\n",
       "   'government',\n",
       "   'has',\n",
       "   'an',\n",
       "   'inherently',\n",
       "   'malevolent',\n",
       "   'influence',\n",
       "   'on',\n",
       "   'society',\n",
       "   'and',\n",
       "   'that',\n",
       "   'it',\n",
       "   'perpetuates',\n",
       "   'dependency',\n",
       "   'and',\n",
       "   'ignorance.',\n",
       "   'he',\n",
       "   'thought',\n",
       "   'that',\n",
       "   'the',\n",
       "   'spread',\n",
       "   'of',\n",
       "   'the',\n",
       "   'use',\n",
       "   'of',\n",
       "   'reason',\n",
       "   'to',\n",
       "   'the',\n",
       "   'masses',\n",
       "   'would',\n",
       "   'eventually',\n",
       "   'cause',\n",
       "   'government',\n",
       "   'to',\n",
       "   'wither',\n",
       "   'away',\n",
       "   'as',\n",
       "   'an',\n",
       "   'unnecessary',\n",
       "   'force.',\n",
       "   'although',\n",
       "   'he',\n",
       "   'did',\n",
       "   'not',\n",
       "   'accord',\n",
       "   'the',\n",
       "   'state',\n",
       "   'with',\n",
       "   'moral',\n",
       "   'legitimacy',\n",
       "   'he',\n",
       "   'was',\n",
       "   'against',\n",
       "   'the',\n",
       "   'use',\n",
       "   'of',\n",
       "   'revolutionary',\n",
       "   'tactics',\n",
       "   'for',\n",
       "   'removing',\n",
       "   'the',\n",
       "   'government',\n",
       "   'from',\n",
       "   'power.',\n",
       "   'rather',\n",
       "   'he',\n",
       "   'advocated',\n",
       "   'for',\n",
       "   'its',\n",
       "   'replacement',\n",
       "   'through',\n",
       "   'process',\n",
       "   'of',\n",
       "   'peaceful',\n",
       "   'evolution.',\n",
       "   'his',\n",
       "   'aversion',\n",
       "   'to',\n",
       "   'the',\n",
       "   'imposition',\n",
       "   'of',\n",
       "   'rules',\n",
       "   'based',\n",
       "   'society',\n",
       "   'led',\n",
       "   'him',\n",
       "   'to',\n",
       "   'denounce',\n",
       "   'as',\n",
       "   'manifestation',\n",
       "   'of',\n",
       "   'the',\n",
       "   'people',\n",
       "   'mental',\n",
       "   'enslavement',\n",
       "   'the',\n",
       "   'foundations',\n",
       "   'of',\n",
       "   'law',\n",
       "   'property',\n",
       "   'rights',\n",
       "   'and',\n",
       "   'even',\n",
       "   'the',\n",
       "   'institution',\n",
       "   'of',\n",
       "   'marriage.',\n",
       "   'he',\n",
       "   'considered',\n",
       "   'the',\n",
       "   'basic',\n",
       "   'foundations',\n",
       "   'of',\n",
       "   'society',\n",
       "   'as',\n",
       "   'constraining',\n",
       "   'the',\n",
       "   'natural',\n",
       "   'development',\n",
       "   'of',\n",
       "   'individuals',\n",
       "   'to',\n",
       "   'use',\n",
       "   'their',\n",
       "   'powers',\n",
       "   'of',\n",
       "   'reasoning',\n",
       "   'to',\n",
       "   'arrive',\n",
       "   'at',\n",
       "   'mutually',\n",
       "   'beneficial',\n",
       "   'method',\n",
       "   'of',\n",
       "   'social',\n",
       "   'organisation.',\n",
       "   'in',\n",
       "   'each',\n",
       "   'case',\n",
       "   'government',\n",
       "   'and',\n",
       "   'its',\n",
       "   'institutions',\n",
       "   'are',\n",
       "   'shown',\n",
       "   'to',\n",
       "   'constrain',\n",
       "   'the',\n",
       "   'development',\n",
       "   'of',\n",
       "   'our',\n",
       "   'capacity',\n",
       "   'to',\n",
       "   'live',\n",
       "   'wholly',\n",
       "   'in',\n",
       "   'accordance',\n",
       "   'with',\n",
       "   'the',\n",
       "   'full',\n",
       "   'and',\n",
       "   'free',\n",
       "   'exercise',\n",
       "   'of',\n",
       "   'private',\n",
       "   'judgement.',\n",
       "   'the',\n",
       "   'french',\n",
       "   'pierre',\n",
       "   'joseph',\n",
       "   'proudhon',\n",
       "   'is',\n",
       "   'regarded',\n",
       "   'as',\n",
       "   'the',\n",
       "   'first',\n",
       "   'self',\n",
       "   'proclaimed',\n",
       "   'anarchist',\n",
       "   'label',\n",
       "   'he',\n",
       "   'adopted',\n",
       "   'in',\n",
       "   'his',\n",
       "   'groundbreaking',\n",
       "   'work',\n",
       "   'what',\n",
       "   'is',\n",
       "   ...],\n",
       "  ('12', 'Anarchism')))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process InputQueue-80:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pipusteky/anaconda3/envs/py36/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/pipusteky/anaconda3/envs/py36/lib/python3.6/site-packages/gensim/utils.py\", line 1193, in run\n",
      "    self.q.put(wrapped_chunk.pop(), block=True)\n",
      "  File \"/home/pipusteky/anaconda3/envs/py36/lib/python3.6/multiprocessing/queues.py\", line 82, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pipusteky/anaconda3/envs/py36/lib/python3.6/multiprocessing/process.py\", line 261, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/pipusteky/anaconda3/envs/py36/lib/python3.6/multiprocessing/util.py\", line 322, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/pipusteky/anaconda3/envs/py36/lib/python3.6/multiprocessing/util.py\", line 262, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/pipusteky/anaconda3/envs/py36/lib/python3.6/multiprocessing/util.py\", line 186, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/pipusteky/anaconda3/envs/py36/lib/python3.6/multiprocessing/queues.py\", line 191, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/pipusteky/anaconda3/envs/py36/lib/python3.6/threading.py\", line 1056, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/pipusteky/anaconda3/envs/py36/lib/python3.6/threading.py\", line 1072, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "next(wiki_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = next(wiki_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_wiki = [next(wiki_iter) for _ in range(142)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(os.path.join(bert_untraced_wiki_folder, 'wiki_sample.pickle'),'wb') as handle:\n",
    "    pickle.dump(sample_wiki, handle, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data.tfrecords', 'wiki_sample.pickle']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(bert_untraced_wiki_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OK LETS TEST `dump_wiki_text_as_tf_records`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Wikipedia_corpus' from '/media/b_drive/sambashare_b/MACHINE_G_DRIVE/MACHINE_G_DRIVE/BERT_MODEL/MODULES/Wikipedia_corpus.py'>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Loading the pre-trained w2v model.\n",
      "--> Finished loading the pre-trained w2v model in 24.314390897750854 s.\n",
      "--> Starting creation of wikipedia iterator.\n",
      "--> Wikipedia iterator prepared in 7609.928758382797 s.\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(wiki)\n",
    "\n",
    "\n",
    "wiki.dump_wiki_text_as_tf_records(path_to_wiki_zipped_corpus =  zipped_wiki_corpus_path,\\\n",
    "                                  path_to_gensim_model = w2v_model_path,\\\n",
    "                                  path_to_save_tf_records = bert_untraced_wiki_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data.tfrecords', 'wiki_sample.pickle']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(bert_untraced_wiki_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## READ THE TF.RECORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11074     8 14541  8222  8588    22  6939    12  1026  7493     1  2782\n",
      "     1    22  5519     1     1  2109     3     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0]\n",
      "[ 791 1591 2436 1579  139   15   60   58   33   84   81    1   34  799\n",
      "  262    3    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "[  170  1579   643  1310  6358   463    82   274    12 11074   969    34\n",
      " 14541 14891    16  1849  2069   103 12349     3     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-185-da1d057bf614>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_util\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbert_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minspect_tf_record_files_one_by_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_untraced_wiki_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'data.tfrecords'\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/media/b_drive/sambashare_b/MACHINE_G_DRIVE/MACHINE_G_DRIVE/BERT_MODEL/MODULES/bert_utils.py\u001b[0m in \u001b[0;36minspect_tf_record_files_one_by_one\u001b[0;34m(path_to_tf_records, name_of_tf_records, upper_bound, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupper_bound\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_record_iter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m   1319\u001b[0m           options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;31m# The threshold to run garbage collection to delete dead tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "importlib.reload(bert_util)\n",
    "bert_util.inspect_tf_record_files_one_by_one(bert_untraced_wiki_folder,'data.tfrecords' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data.tfrecords', 'wiki_sample.pickle']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(bert_untraced_wiki_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(bert_untraced_wiki_folder, 'data.tfrecords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_iterator(filenames: list,\\\n",
    "                   eos_token = True,\\\n",
    "                  max_sequence_length = 40):\n",
    "    \n",
    "    \"\"\"\n",
    "    first and foremost; \n",
    "    \n",
    "    since the max_sequence_length:: DOES NOT include the `eos` and `bos` tokens\n",
    "    you MUST add 2\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def parse_and_pad(seq, max_sequence_length):\n",
    "        sequence_features = {'tokens':tf.FixedLenSequenceFeature([], dtype=tf.int64)}\n",
    "        \n",
    "        _, sequence_parsed = tf.parse_single_sequence_example(serialized=seq,\\\n",
    "                                                             sequence_features=sequence_features)\n",
    "        \n",
    "        t = sequence_parsed['tokens']\n",
    "        \n",
    "        if eos_token:\n",
    "            t = tf.pad(t, [[0,1]], constant_values=3)\n",
    "        \n",
    "        \n",
    "        return tf.pad(t, [[0, max_sequence_length - tf.shape(t)[0]]])\n",
    "    \n",
    "    # -------------- CODE ------------------------\n",
    "    # you must add 2; because of <eos> and <bos> tokens\n",
    "    max_sequence_length += 2\n",
    "    \n",
    "    dataset = tf.data.TFRecordDataset(filenames)\n",
    "    \n",
    "    dataset = dataset.map(lambda t, sent_length = max_sequence_length: parse_and_pad(t, sent_length))\n",
    "    \n",
    "    return dataset.prefetch(1).make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = tf.constant([[1.0, 2.0], [3.0, 4.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range_iterator"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(iter(range(12)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pipusteky/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "session = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itern = train_iterator(data_path)\n",
    "\n",
    "[tf.shape(itern.get_next())[0].eval() for _ in range(12)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Iterator' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-161-f6d41dc44808>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mitern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtenx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtenx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'Iterator' object is not iterable"
     ]
    }
   ],
   "source": [
    "itern = train_iterator(data_path)\n",
    "\n",
    "[(ind, tenx.eval()) for (ind, tenx) in enumerate(itern)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intherm(INX:'Iterator'):\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            yield INX.get_next()\n",
    "            \n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "        \n",
    "        except:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pipusteky/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py:407: UserWarning: An unusually high number of `Iterator.get_next()` calls was detected. This often indicates that `Iterator.get_next()` is being called inside a training loop, which will cause gradual slowdown and eventual resource exhaustion. If this is the case, restructure your code to call `next_element = iterator.get_next()` once outside the loop, and use `next_element` as the input to some computation that is invoked inside the loop.\n",
      "  warnings.warn(GET_NEXT_CALL_WARNING_MESSAGE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[  274    12   148  8726 11074  4085    21    43  3864     1  5758     1\n",
      "   676     1   794     1  6022   869    15   945  4306     7   274    12\n",
      " 11074  4530     1    20  1440     3     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0]\n",
      "1\n",
      "[  325     1  4151 18585   643  8426     1    20   812     6   137    12\n",
      " 11074     3     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0]\n",
      "2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-176-19bf4e46e39b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtfx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintherm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m     \"\"\"\n\u001b[0;32m--> 713\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5155\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5156\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 5157\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for ind, tfx in enumerate(intherm(itern)):\n",
    "    print(ind)\n",
    "    print(tfx.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pipusteky/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py:407: UserWarning: An unusually high number of `Iterator.get_next()` calls was detected. This often indicates that `Iterator.get_next()` is being called inside a training loop, which will cause gradual slowdown and eventual resource exhaustion. If this is the case, restructure your code to call `next_element = iterator.get_next()` once outside the loop, and use `next_element` as the input to some computation that is invoked inside the loop.\n",
      "  warnings.warn(GET_NEXT_CALL_WARNING_MESSAGE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1250  4399     1 11074  3629     5    15   584  1385     1  1408    17\n",
      "     1  4896  1688   298  3270   322 14558     1  2674    21   945 15902\n",
      "     3     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0]\n",
      "[ 1026   361  1026  8610 13634 11074     1    15   738 11074  6554 12686\n",
      "     1   162 12997    21    70 14541 12686     3     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0]\n",
      "[   72    12 11074    25  1026     1     1   643  1387    15     1    50\n",
      "   492     7   135    72   146     6  2817     3     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0]\n",
      "[ 1233     1 10082     1  1327    71  7048     1  1140    15  1026  2782\n",
      "     1     1    33    72    12  1849     1   361    18  1269    71  1802\n",
      "    91    31     1     9     1  3485  1026   361  2544  4008   286     5\n",
      "  5454     3     0     0     0     0]\n",
      "[    1 11143   265   377  1148     1  1026     1  4884     1   333    16\n",
      "   492   377   643     1  2527   377     1    34   254   525     3     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0]\n",
      "[    1 19741  8515    43     1    21  1026 13611     6  1030    36    25\n",
      "   377  2054  1162     1   753   456     1    62    17    25    15   903\n",
      "     1   208  1608  6280     1  4329   913   140    18  5691    16   341\n",
      "     3     0     0     0     0     0]\n",
      "[   84     1   165    40   158   274    12 11074    23   377   466     1\n",
      "  4702  1026  2414  1251   492     1     1     1  2527     1  7266  5732\n",
      "     1     1   146  2827    12   492     3     0     0     0     0     0\n",
      "     0     0     0     0     0     0]\n",
      "[  717    36    62   819     1     1    34  1465 13741     3     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0]\n",
      "[  110   274    12 11074  2037 17705   377 17908   375    64     1   274\n",
      "  1025    32  1571     1     5   274    12   507  5133   361    33   377\n",
      "  2674     1     3     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0]\n",
      "[1742  274    1 2283   12    1 2160 2062    9 2099    1  505    1 7870\n",
      " 3235 1025   32  141   20 4749  489    1  690  903    1 6624  575  254\n",
      " 7266    3    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "for ind in range(10):\n",
    "    if ind>=_upper_bound:\n",
    "        break\n",
    "        \n",
    "    try:\n",
    "        next_one = itern.get_next()\n",
    "        print(next_one.eval())\n",
    "        _counter+=1\n",
    "        \n",
    "    except tf.errors.OutOfRangeError:\n",
    "        break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pipusteky/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py:407: UserWarning: An unusually high number of `Iterator.get_next()` calls was detected. This often indicates that `Iterator.get_next()` is being called inside a training loop, which will cause gradual slowdown and eventual resource exhaustion. If this is the case, restructure your code to call `next_element = iterator.get_next()` once outside the loop, and use `next_element` as the input to some computation that is invoked inside the loop.\n",
      "  warnings.warn(GET_NEXT_CALL_WARNING_MESSAGE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1025   76    8   90  519 7999   76   25   46  887    1  274   35 2981\n",
      "    3    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "[   17   135   274    12 11074   592  8983    59  2774     1   463    82\n",
      "    23  1123     3     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0]\n",
      "[   31     1  2038    28  1341    12    82  1669  1244  7999     1   492\n",
      "  8827 11074   134    20  2257    18  1571     1    17  2111    18  8222\n",
      "     3     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0]\n",
      "[ 6116 11074     8  1300     1  2224     3     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0]\n",
      "[ 468   85   72   18    1    5   15   15  250    1   72 1606   14 1300\n",
      "   16  283   72 1515    3    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "[   5   15 1341  527   50    3    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "[  297     1   274    23  4907    12     1    43    64 10404    21     3\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0]\n",
      "[ 403    5    5   15 7929  748    3    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "[  19 7286  138    1  165  364   43  643    5 1640   64 1344    3    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "[   15   250     1    72  4907    28   665  4743   144    15  4749   489\n",
      "     1   730     5 11421   929    15   805     1   373  2773  1037    25\n",
      "   665     8 17504     3     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-170-7a51ae3c7cdf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mnext_one\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_one\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0m_counter\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m     \"\"\"\n\u001b[0;32m--> 713\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5155\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5156\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 5157\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "_counter = 0\n",
    "_upper_bound = 12\n",
    "while True:\n",
    "    if _counter>=_upper_bound:\n",
    "        break\n",
    "        \n",
    "    try:\n",
    "        next_one = itern.get_next()\n",
    "        print(next_one.eval())\n",
    "        _counter+=1\n",
    "        \n",
    "    except tf.errors.OutOfRangeError:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-115-431a18235d5d>:14: Print (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2018-08-20.\n",
      "Instructions for updating:\n",
      "Use tf.print instead of tf.Print. Note that tf.print returns a no-output operator that directly prints the output. Outside of defuns or eager mode, this operator will not be executed unless it is directly specified in session.run or used as a control dependency for other operators. This is only a concern in graph mode. Below is an example of how to ensure tf.print executes in graph mode:\n",
      "```python\n",
      "    sess = tf.Session()\n",
      "    with sess.as_default():\n",
      "        tensor = tf.range(10)\n",
      "        print_op = tf.print(tensor)\n",
      "        with tf.control_dependencies([print_op]):\n",
      "          out = tf.add(tensor, tensor)\n",
      "        sess.run(out)\n",
      "    ```\n",
      "Additionally, to use tf.print in python 2.7, users must make sure to import\n",
      "the following:\n",
      "\n",
      "  `from __future__ import print_function`\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Print() missing 1 required positional argument: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-02712fa26860>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mkkt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-115-431a18235d5d>\u001b[0m in \u001b[0;36mtrain_iterator\u001b[0;34m(filenames, eos_token, max_sequence_length)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFRecordDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparse_and_pad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_one_shot_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls)\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \"\"\"\n\u001b[1;32m   1037\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mParallelMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism)\u001b[0m\n\u001b[1;32m   2609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2610\u001b[0m     wrapped_func = StructuredFunctionWrapper(\n\u001b[0;32m-> 2611\u001b[0;31m         map_func, \"Dataset.map()\", input_dataset)\n\u001b[0m\u001b[1;32m   2612\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2613\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_shapes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, add_to_graph, experimental_nested_dataset_support)\u001b[0m\n\u001b[1;32m   1858\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_data_structured_function_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1859\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1861\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m       \u001b[0;31m# Use the private method that will execute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/function.py\u001b[0m in \u001b[0;36madd_to_graph\u001b[0;34m(self, g)\u001b[0m\n\u001b[1;32m    477\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;34m\"\"\"Adds this function into the graph g.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_definition_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Adds this function into 'g'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/function.py\u001b[0m in \u001b[0;36m_create_definition_if_needed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;34m\"\"\"Creates the function definition if it's not created yet.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_definition_if_needed_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_definition_if_needed_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/function.py\u001b[0m in \u001b[0;36m_create_definition_if_needed_impl\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    342\u001b[0m     temp_graph = func_graph_from_py_func(\n\u001b[1;32m    343\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_arg_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_arg_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m         self._capture_by_value, self._caller_device)\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extra_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/function.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(func, arg_names, arg_types, name, capture_by_value, device, colocation_stack, container, collections_ref, arg_shapes)\u001b[0m\n\u001b[1;32m    862\u001b[0m     \u001b[0;31m# Call func and gather the output tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 864\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m     \u001b[0;31m# There is no way of distinguishing between a function not returning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mtf_data_structured_function_wrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   1792\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1794\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1795\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1796\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-115-431a18235d5d>\u001b[0m in \u001b[0;36mparse_and_pad\u001b[0;34m(seq)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstant_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPrint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_sequence_length\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m               instructions)\n\u001b[0;32m--> 306\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    308\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Print() missing 1 required positional argument: 'data'"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    kkt = train_iterator(data_path)\n",
    "    \n",
    "    for _ in range(12):\n",
    "        print(kkt.get_next().eval())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'with'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim_model.index2entity[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([11074,     8, 14541,  8222,  8588,    22,  6939,    12,  1026,\n",
       "         7493,     1,  2782,     1,    22,  5519,     1,     1,  2109,\n",
       "            3,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0]),\n",
       " array([ 791, 1591, 2436, 1579,  139,   15,   60,   58,   33,   84,   81,\n",
       "           1,   34,  799,  262,    3,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  170,  1579,   643,  1310,  6358,   463,    82,   274,    12,\n",
       "        11074,   969,    34, 14541, 14891,    16,  1849,  2069,   103,\n",
       "        12349,     3,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0])]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.TFRecordDataset(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'PrefetchDataset' object is not an iterator",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-ff675a2ee99e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'PrefetchDataset' object is not an iterator"
     ]
    }
   ],
   "source": [
    "print(next(x.make_one_shot_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEW HUGE WIKIPEDIA FILE TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf_record_batch_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'bert_utils' from '/media/b_drive/sambashare_b/MACHINE_G_DRIVE/MACHINE_G_DRIVE/BERT_MODEL/MODULES/bert_utils.py'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(bert_util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['enwiki-latest-pages-articles.xml.bz2']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(wiki_corpus_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'bert_utils' from '/media/b_drive/sambashare_b/MACHINE_G_DRIVE/MACHINE_G_DRIVE/BERT_MODEL/MODULES/bert_utils.py'>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(bert_util)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(bert_util)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tens_iter = bert_util.tf_record_batch_iterator(os.path.join(bert_untraced_wiki_folder,\\\n",
    "                                                                'data.tfrecords'),batch_size = 142, time_major = False)\n",
    "    \n",
    "    true_tens = sess.run(tens_iter.get_next())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    1,     8,   454, ...,     0,     0,     0],\n",
       "       [  170,  2191,    23, ...,     0,     0,     0],\n",
       "       [    1,  2241, 14253, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [   34, 19082,   270, ...,     0,     0,     0],\n",
       "       [    1,   760,  1820, ...,     0,     0,     0],\n",
       "       [    1,     1,  3409, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reshape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    1     8   454 ...     0     0     0]\n",
      " [  170  2191    23 ...     0     0     0]\n",
      " [    1  2241 14253 ...     0     0     0]\n",
      " ...\n",
      " [  295     1     1 ...    31     3     0]\n",
      " [    1     8  2269 ...     0     0     0]\n",
      " [   26  2722     5 ...     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(bert_util)\n",
    "bert_util.inspect_batch_of_tf_record_files(bert_untraced_wiki_folder, 'data.tfrecords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data.tfrecords', 'wiki_sample.pickle']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(bert_untraced_wiki_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range_iterator"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(iter(range(12)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
